{
    "train_args": {
    	"model_name_or_path": "xlm-roberta-large", 
        "output_dir": "./models/roberta-large-epoch-10-lr",
        "num_train_epochs": 10,
        "save_total_limit": 1,
	"save_steps": 100,
	"warmup_steps": 300,
	"weight_decay": 0.01,
	"logging_steps": 100,
	"dataloader_num_workers": 4,
	"learning_rate": 1e-5,
	"label_smoothing_factor": 0.5
    },
    "inference_args": {
        "output_dir": "./outputs/roberta-large-epoch-10-lr"
    }
}
